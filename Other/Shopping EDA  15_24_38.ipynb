{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ade68e-dd51-4bb1-957f-7975a4fcf4e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting et-xmlfile (from openpyxl)\n  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\nDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\nDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nInstalling collected packages: et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b67f8bcf-e006-41a0-bcca-ca4f0b9ae41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84f11c5-5a13-4437-a7a5-0a27ebcd9d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import numpy for numerical operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c55f6f43-cc45-40c9-8387-e6b54e00aaf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Read excel file \n",
    "data_path= \"practical.retail.shoping_trends\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af030085-c5ca-43cd-89c0-8c1aa4799153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8798984957541863>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the data from DBFS after uploading the file\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/dbfs/FileStore/practical.retail.shoping_trends.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m      4\u001B[0m )\n",
       "\u001B[1;32m      5\u001B[0m display(df)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001B[0m, in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n",
       "\u001B[1;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n",
       "\u001B[1;32m    494\u001B[0m     should_close \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 495\u001B[0m     io \u001B[38;5;241m=\u001B[39m ExcelFile(\n",
       "\u001B[1;32m    496\u001B[0m         io,\n",
       "\u001B[1;32m    497\u001B[0m         storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n",
       "\u001B[1;32m    498\u001B[0m         engine\u001B[38;5;241m=\u001B[39mengine,\n",
       "\u001B[1;32m    499\u001B[0m         engine_kwargs\u001B[38;5;241m=\u001B[39mengine_kwargs,\n",
       "\u001B[1;32m    500\u001B[0m     )\n",
       "\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;241m!=\u001B[39m io\u001B[38;5;241m.\u001B[39mengine:\n",
       "\u001B[1;32m    502\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    503\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    504\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    505\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001B[0m, in \u001B[0;36mExcelFile.__init__\u001B[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[0m\n",
       "\u001B[1;32m   1548\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m-> 1550\u001B[0m     ext \u001B[38;5;241m=\u001B[39m inspect_excel_format(\n",
       "\u001B[1;32m   1551\u001B[0m         content_or_path\u001B[38;5;241m=\u001B[39mpath_or_buffer, storage_options\u001B[38;5;241m=\u001B[39mstorage_options\n",
       "\u001B[1;32m   1552\u001B[0m     )\n",
       "\u001B[1;32m   1553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m   1554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1555\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExcel file format cannot be determined, you must specify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1556\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man engine manually.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1557\u001B[0m         )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001B[0m, in \u001B[0;36minspect_excel_format\u001B[0;34m(content_or_path, storage_options)\u001B[0m\n",
       "\u001B[1;32m   1399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n",
       "\u001B[1;32m   1400\u001B[0m     content_or_path \u001B[38;5;241m=\u001B[39m BytesIO(content_or_path)\n",
       "\u001B[0;32m-> 1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n",
       "\u001B[1;32m   1403\u001B[0m     content_or_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m, storage_options\u001B[38;5;241m=\u001B[39mstorage_options, is_text\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[1;32m   1404\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handle:\n",
       "\u001B[1;32m   1405\u001B[0m     stream \u001B[38;5;241m=\u001B[39m handle\u001B[38;5;241m.\u001B[39mhandle\n",
       "\u001B[1;32m   1406\u001B[0m     stream\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/common.py:882\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n",
       "\u001B[1;32m    873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n",
       "\u001B[1;32m    874\u001B[0m             handle,\n",
       "\u001B[1;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    879\u001B[0m         )\n",
       "\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n",
       "\u001B[0;32m--> 882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
       "\u001B[1;32m    883\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n",
       "\u001B[1;32m    885\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mOSError\u001B[0m: [Errno 5] Input/output error: '/dbfs/FileStore/practical.retail.shoping_trends.xlsx'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "OSError",
        "evalue": "[Errno 5] Input/output error: '/dbfs/FileStore/practical.retail.shoping_trends.xlsx'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>OSError</span>: [Errno 5] Input/output error: '/dbfs/FileStore/practical.retail.shoping_trends.xlsx'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
        "File \u001B[0;32m<command-8798984957541863>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the data from DBFS after uploading the file\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/dbfs/FileStore/practical.retail.shoping_trends.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m display(df)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001B[0m, in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[1;32m    494\u001B[0m     should_close \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 495\u001B[0m     io \u001B[38;5;241m=\u001B[39m ExcelFile(\n\u001B[1;32m    496\u001B[0m         io,\n\u001B[1;32m    497\u001B[0m         storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[1;32m    498\u001B[0m         engine\u001B[38;5;241m=\u001B[39mengine,\n\u001B[1;32m    499\u001B[0m         engine_kwargs\u001B[38;5;241m=\u001B[39mengine_kwargs,\n\u001B[1;32m    500\u001B[0m     )\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;241m!=\u001B[39m io\u001B[38;5;241m.\u001B[39mengine:\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    503\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    505\u001B[0m     )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001B[0m, in \u001B[0;36mExcelFile.__init__\u001B[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[0m\n\u001B[1;32m   1548\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1550\u001B[0m     ext \u001B[38;5;241m=\u001B[39m inspect_excel_format(\n\u001B[1;32m   1551\u001B[0m         content_or_path\u001B[38;5;241m=\u001B[39mpath_or_buffer, storage_options\u001B[38;5;241m=\u001B[39mstorage_options\n\u001B[1;32m   1552\u001B[0m     )\n\u001B[1;32m   1553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1555\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExcel file format cannot be determined, you must specify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1556\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man engine manually.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1557\u001B[0m         )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001B[0m, in \u001B[0;36minspect_excel_format\u001B[0;34m(content_or_path, storage_options)\u001B[0m\n\u001B[1;32m   1399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[1;32m   1400\u001B[0m     content_or_path \u001B[38;5;241m=\u001B[39m BytesIO(content_or_path)\n\u001B[0;32m-> 1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n\u001B[1;32m   1403\u001B[0m     content_or_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m, storage_options\u001B[38;5;241m=\u001B[39mstorage_options, is_text\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1404\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[1;32m   1405\u001B[0m     stream \u001B[38;5;241m=\u001B[39m handle\u001B[38;5;241m.\u001B[39mhandle\n\u001B[1;32m   1406\u001B[0m     stream\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/io/common.py:882\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    874\u001B[0m             handle,\n\u001B[1;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    879\u001B[0m         )\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m--> 882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    883\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[1;32m    885\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
        "\u001B[0;31mOSError\u001B[0m: [Errno 5] Input/output error: '/dbfs/FileStore/practical.retail.shoping_trends.xlsx'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "# Load the data from DBFS after uploading the file\n",
    "df = pd.read_excel(\n",
    "    '/dbfs/FileStore/practical.retail.shoping_trends.xlsx'\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b8ea4a-4fa8-4028-9d3f-6b69d83e7cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8798984957541869>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#display the data\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m display (df)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'df' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'df' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8798984957541869>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#display the data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m display (df)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display the data\n",
    "display (df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5b0a5e-f730-49cc-a797-0746d9ae5697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8798984957541870>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Displays a concise summary of the DataFrame, including the number of non-null entries and data types for each\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39minfo()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'df' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'df' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8798984957541870>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Displays a concise summary of the DataFrame, including the number of non-null entries and data types for each\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39minfo()\n",
        "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displays a concise summary of the DataFrame, including the number of non-null entries and data types for each\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99612153-f58a-492a-b86b-518c5c53be07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Displays the column labels of the DataFrame\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8de95689-17be-4c5a-8b6b-c5c7c99bb4c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8798984957541872>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Returns the first 5 rows of the DataFrame\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'df' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'df' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8798984957541872>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Returns the first 5 rows of the DataFrame\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Returns the first 5 rows of the DataFrame\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Shopping EDA  15:24:38",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}